{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZw3lh8d_e8N"
   },
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kR3KBPXsSAvs"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_fn = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/Data/\"\n",
    "onlyfiles = [f for f in listdir(data_fn) if isfile(join(data_fn, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b3fa098265cb41a491a00db86483b1d5",
      "761dfdab66bf4abf8b4b5be7041edaa0",
      "27a3c8ce545f477d8b3cb2d4358b72aa",
      "f007e15b78cf449c8d93945b0a5378d7",
      "4e9cd596a218497a94940db9ee24471d",
      "78b3403352eb4fc68274d87602e3fa38",
      "0dff3ccc15ab40399ea1b3749c9e7f01",
      "709f170efcf74bd484939ba2ff39dfb1",
      "a368c89b81e3463a822042826c25b5c9",
      "8da11b77ccb2437cb1ceaa82a30986ac",
      "530861e7ab3146cd85d239b36fe8c228"
     ]
    },
    "id": "7hy9Fp9ASNej",
    "outputId": "66b4afe7-7ff8-4eb8-a565-4117d346ccb9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "sum = torch.Tensor([0., 0., 0.]).to(device)\n",
    "sq_sum = torch.Tensor([0., 0., 0.]).to(device)\n",
    "count = 0\n",
    "for fn in tqdm(onlyfiles):\n",
    "    image = transform(pil_loader(data_fn + fn)).to(device)\n",
    "    _, n, m = image.shape\n",
    "    sum += image.sum((1, 2))\n",
    "    sq_sum += (image**2).sum((1, 2))\n",
    "    count += n * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jyDjeQ1bNRT"
   },
   "outputs": [],
   "source": [
    "means = sum/count\n",
    "stds = torch.sqrt(sq_sum/count - means**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P80cTK_PbRX2",
    "outputId": "dc813ba0-9858-429a-af5c-e73170ade6cb"
   },
   "outputs": [],
   "source": [
    "means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDEHfMGkGV8J"
   },
   "source": [
    "### Δεδομένα στο Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYHloEqmDJKY",
    "outputId": "4e1a0208-6fb7-469e-d3d0-30e385714838"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf69K7s6PLiz"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "* transforms\n",
    "* τροπος που φορτωνονται τα δεδομενα\n",
    "* augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i54tTXN2-rv8"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "\n",
    "class Artists(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_path, image_ids_fn, images_dir, train):\n",
    "        self.base_path = base_path\n",
    "        self.image_ids_fn = image_ids_fn\n",
    "        self.images_dir = images_dir\n",
    "        with open(base_path + image_ids_fn, 'r') as fp:\n",
    "            rows = list(fp)\n",
    "            self.fnames = [s.strip().split(',')[0] for s in rows[1:]]\n",
    "            self.img_class_ids = [int(s.strip().split(',')[1]) for s in rows[1:]]\n",
    "            self.img_ids = list(range(len(self.fnames)))\n",
    "        self.train = train\n",
    "        self.transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5138, 0.4915, 0.4315], [0.2675, 0.2572, 0.2626])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5138, 0.4915, 0.4315], [0.2675, 0.2572, 0.2626])\n",
    "            ]),\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_fname = self.fnames[index]\n",
    "        image = pil_loader(self.base_path + self.images_dir + img_fname)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            if self.train:\n",
    "                image = self.transform['train'](image)\n",
    "            else:\n",
    "                image = self.transform['val'](image)\n",
    "        return image, self.img_class_ids[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOS59AIPPlfj"
   },
   "source": [
    "### Μοντέλο\n",
    "\n",
    "* αρχιτεκτονικη\n",
    "* βαθος cnn\n",
    "* βαθος fc\n",
    "* regularization\n",
    "* fine-tuning/freeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qdu2fqtzHmFA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNet34Small(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet34Small, self).__init__()\n",
    "        original_model = models.resnet34(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-3])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RegNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(RegNet, self).__init__()\n",
    "        original_model = models.regnet_y_800mf(pretrained=True)\n",
    "        self.features = nn.Sequential(original_model.stem, *list(original_model.trunk_output.children()))\n",
    "        self.features.requires_grad = False\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LazyLinear(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def finetune(self, n_layers):\n",
    "        for child in list((net.features[1]).children())[-n_layers:]:\n",
    "            child.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YTNZjsfdh8W"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dwa1glfBd1Zs"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.transforms import ToTensor\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "def run(net, device, loader, optimizer, scheduler, split='val', epoch=0, train=False,\n",
    "        dry_run=False):\n",
    "    if train:\n",
    "        net.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        net.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    \n",
    "    loader = tqdm(\n",
    "        loader,\n",
    "        ncols=0,\n",
    "        desc='{1} E{0:02d}'.format(epoch, 'train' if train else 'val')\n",
    "    )\n",
    "    \n",
    "    running_loss = 0\n",
    "    preds_all = []\n",
    "    labels_all = []\n",
    "    for (imgs, img_class_ids) in loader:\n",
    "        imgs, img_class_ids = (\n",
    "            imgs.to(device), img_class_ids.to(device).long()\n",
    "        )\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            output = net(imgs)\n",
    "            loss = F.cross_entropy(output, img_class_ids, label_smoothing=1e-2)\n",
    "\n",
    "        _, preds = torch.max(output, 1)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        labels_all.extend(img_class_ids.cpu().numpy())\n",
    "        preds_all.extend(preds.cpu().numpy())\n",
    "        \n",
    "        if dry_run:\n",
    "            break\n",
    "    \n",
    "    if train:\n",
    "        scheduler.step()\n",
    "        \n",
    "    bal_acc = metrics.balanced_accuracy_score(labels_all, preds_all)\n",
    "\n",
    "    print('Epoch: {}.. '.format(epoch),\n",
    "        '{} Loss: {:.3f}.. '.format(split, running_loss / len(loader)),\n",
    "        '{} Accuracy: {:.3f}.. '.format(split, bal_acc),\n",
    "    )\n",
    "    \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "def train(net, base_path, train_ids_fn, val_ids_fn, images_dir, model_fname,\n",
    "          batch_size=16, lr=1e-2, warmup=0, n_layers = 0, epochs=10,\n",
    "          device='cpu', num_workers=6, dry_run=False):\n",
    "\n",
    "    train_dataset = Artists(base_path, train_ids_fn, images_dir, True)\n",
    "    val_dataset = Artists(base_path, val_ids_fn, images_dir, False)\n",
    "\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    cur_best_val_loss = np.inf\n",
    "\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad,\n",
    "        net.parameters()), lr=lr, momentum=0.9)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(warmup):\n",
    "        _ = run(net, device, train_loader, optimizer, scheduler, split='train',\n",
    "                    epoch=epoch, train=True, dry_run=dry_run)\n",
    "        val_loss = run(net, device, val_loader, optimizer, scheduler, split='val',\n",
    "                    epoch=epoch, train=False, dry_run=dry_run)      \n",
    "        if dry_run:\n",
    "            break\n",
    "    \n",
    "    net.finetune(n_layers)\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad,\n",
    "        net.parameters()), lr=lr, momentum=0.9)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        _ = run(net, device, train_loader, optimizer, scheduler, split='train',\n",
    "                    epoch=epoch, train=True, dry_run=dry_run)\n",
    "        val_loss = run(net, device, val_loader, optimizer, scheduler, split='val',\n",
    "                    epoch=epoch, train=False, dry_run=dry_run)\n",
    "\n",
    "        if cur_best_val_loss > val_loss:\n",
    "            if epoch > 0:\n",
    "                # remove previous best model\n",
    "                os.remove(model_fname)\n",
    "            torch.save(net.state_dict(), model_fname)\n",
    "            cur_best_val_loss = val_loss\n",
    "        \n",
    "        if dry_run:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7OMAPtUI-sQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/\"\n",
    "# base_path = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/\"\n",
    "train_ids_fname = \"train_100.csv\"\n",
    "val_ids_fname = \"val_100.csv\"\n",
    "images_dir = \"Data/\"\n",
    "model_fname = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/resnet.pt\"\n",
    "# model_fname = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/resnet.pt\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "net = ResNet34Small(20).to(device)\n",
    "\n",
    "train(net, base_path, train_ids_fname, val_ids_fname,\n",
    "      images_dir, model_fname, device=device, warmup=2,\n",
    "      epochs=10, lr=5e-5, batch_size=16, dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 500/\"\n",
    "# base_path = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/\"\n",
    "train_ids_fname = \"train_500.csv\"\n",
    "val_ids_fname = \"val_500.csv\"\n",
    "images_dir = \"Data/\"\n",
    "model_fname = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 500/regnet_800_finetuned.pt\"\n",
    "# model_fname = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/regnet.pt\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "net = RegNet(20).to(device)\n",
    "\n",
    "train(net, base_path, train_ids_fname, val_ids_fname, images_dir,\n",
    "      model_fname, device=device, warmup=3, n_layers=4,\n",
    "      epochs=20, lr=1e-3, batch_size=16, dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/\"\n",
    "# base_path = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/\"\n",
    "train_ids_fname = \"train_100.csv\"\n",
    "val_ids_fname = \"val_100.csv\"\n",
    "images_dir = \"Data/\"\n",
    "model_fname = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/regnet_4layers.pt\"\n",
    "# model_fname = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/regnet.pt\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "net = RegNet(20).to(device)\n",
    "\n",
    "train(net, base_path, train_ids_fname, val_ids_fname, images_dir,\n",
    "      model_fname, device=device, warmup=2, n_layers=4,\n",
    "      epochs=24, lr=5e-4, batch_size=16, dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eikXM0IP0XN"
   },
   "source": [
    "### Feature extraction από CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmczXhx5EilL"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "base_path = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/\"\n",
    "train_pkl = \"train_100.pkl\"\n",
    "val_pkl = \"val_100.pkl\"\n",
    "test_pkl = \"test_100.pkl\"\n",
    "net = ResNet34Small(20)\n",
    "checkpoint = torch.load(\"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/resnet.pt\")\n",
    "net.load_state_dict(checkpoint)\n",
    "with open(base_path + train_pkl,\"rb\") as f:\n",
    "  train_dataset = pickle.load(f)\n",
    "with open(base_path + test_pkl,\"rb\") as f:\n",
    "  test_dataset = pickle.load(f)\n",
    "with open(base_path + val_pkl,\"rb\") as f:\n",
    "  val_dataset = pickle.load(f)\n",
    "\n",
    "painting_features_train = [(net.features(x.unsqueeze(0)).flatten().numpy(), y) for x, y in train_dataset]\n",
    "painting_features_val = [(net.features(x.unsqueeze(0).flatten()).numpy(),y) for x, y in val_dataset]\n",
    "painting_features_test = [(net.features(x.unsqueeze(0).flatten()).numpy(),y) for x, y in test_dataset]\n",
    "paintings = {\"train\":painting_features_train, \"test\":painting_features_test, \"val\":painting_features_val} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPJqKX1HD4s-"
   },
   "outputs": [],
   "source": [
    "output = open('painting_features.pkl', 'wb')\n",
    "pickle.dump(datasets, output)\n",
    "output.close()\n",
    "!cp painting_features.pkl '/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regnet_y_400mf = models.regnet_y_400mf(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(regnet_y_400mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[x for x, _ in regnet_y_400mf.named_children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regnet_y_400mf.avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x, _ in regnet_y_400mf.trunk_output.named_children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(regnet_y_400mf.trunk_output.block1[0].named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regnet_y_400mf.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/\"\n",
    "# base_path = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/\"\n",
    "train_ids_fn = \"train_100.csv\"\n",
    "val_ids_fn = \"val_100.csv\"\n",
    "images_dir = \"Data/\"\n",
    "model_fname = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 100/regnet.pt\"\n",
    "train_dataset = Artists(base_path, train_ids_fn, images_dir, True)\n",
    "val_dataset = Artists(base_path, val_ids_fn, images_dir, False)\n",
    "batch_size = 16\n",
    "num_workers = 8\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_model = models.regnet_y_800mf()\n",
    "len(list(original_model.trunk_output.named_children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 500/\"\n",
    "# base_path = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/\"\n",
    "# train_ids_fname = \"train_500.csv\"\n",
    "# val_ids_fname = \"val_500.csv\"\n",
    "test_ids_fname = \"test_500.csv\"\n",
    "\n",
    "images_dir = \"Data/\"\n",
    "model_fname = \"/home/jason/Desktop/projects/masters/ml/group_project/Dataset 500/regnet_800_long_train.pt\"\n",
    "# model_fname = \"/content/gdrive/My Drive/art_recognition/Datasets/Dataset 100/regnet.pt\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "net = RegNet(20).to(device)\n",
    "net.load_state_dict(torch.load('/home/jason/Desktop/projects/masters/ml/group_project/\\\n",
    "Dataset 500/regnet_800_finetuned.pt'))\n",
    "\n",
    "# train_dataset = Artists(base_path, train_ids_fname, images_dir, False)\n",
    "# val_dataset = Artists(base_path, val_ids_fname, images_dir, False)\n",
    "test_dataset = Artists(base_path, test_ids_fname, images_dir, False)\n",
    "\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=16,\n",
    "#     num_workers=8,\n",
    "#     shuffle=False,\n",
    "# )\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=16,\n",
    "#     num_workers=8,\n",
    "#     shuffle=False,\n",
    "# )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    "    shuffle=False,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(net, device, test_loader, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat = torch.flatten(net.avgpool(net.features(X)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat.to('cpu').detach().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_feat = X_feat.to('cpu').detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_feat = torch.cat((torch.Tensor(), X_feat.to('cpu').detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = torch.Tensor(), torch.Tensor()\n",
    "for X, y in train_loader:\n",
    "    X = X.to(device)\n",
    "    X = torch.flatten(net.avgpool(net.features(X)), 1)\n",
    "    X_train = torch.cat((X_train, X.to('cpu').detach()))\n",
    "    \n",
    "    y_train = torch.cat((y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = torch.Tensor(), torch.Tensor()\n",
    "for X, y in test_loader:\n",
    "    X = X.to(device)\n",
    "    X = torch.flatten(net.avgpool(net.features(X)), 1)\n",
    "    X_test = torch.cat((X_test, X.to('cpu').detach()))  \n",
    "    y_test = torch.cat((y_test, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = X_test.numpy(), y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"test_features.pickle\", 'wb') as f:\n",
    "    pickle.dump((X_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"train_features.pickle\", 'wb') as f:\n",
    "    pickle.dump((X_train, y_train), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier()\n",
    "strategy = ['stratified', 'most_frequent', 'prior', 'uniform']\n",
    "param_grid = [\n",
    "    {'clf__strategy': ['stratified', 'most_frequent', 'prior', 'uniform']},\n",
    "    {'clf__strategy': ['constant'], 'clf__constant': [0, 1]},\n",
    "]\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', clf)], memory='tmp')\n",
    "estimator = GridSearchCV(pipe, param_grid, cv=10, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(estimator.cv_results_)[\n",
    "    ['mean_fit_time', 'params', 'mean_test_score', 'std_test_score', 'rank_test_score']\n",
    "].sort_values(by=['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "param_grid = [{\n",
    "    'clf__solver': ['liblinear'],\n",
    "    'clf__penalty': ['l2', 'l1'],\n",
    "    'clf__C': [0.1, 1.0, 10.0]\n",
    "#     }, {\n",
    "#     'clf__solver': ['lbfgs'],\n",
    "#     'clf__penalty': ['l2'],\n",
    "#     'clf__C': [0.1, 1.0, 10.0]\n",
    "#     }, {\n",
    "#     'clf__solver': ['lbfgs'],\n",
    "#     'clf__penalty': ['none']\n",
    "#     }, {\n",
    "#     'clf__solver': ['sag'],\n",
    "#     'clf__penalty': ['l2'],\n",
    "#     'clf__C': [0.1, 1.0, 10.0]\n",
    "#     }, {\n",
    "#     'clf__solver': ['sag'],\n",
    "#     'clf__penalty': ['none']\n",
    "#     }, {\n",
    "#     'clf__solver': ['saga'],\n",
    "#     'clf__penalty': ['l2', 'l1'],\n",
    "#     'clf__C': [0.1, 1.0, 10.0]\n",
    "#     }, {\n",
    "#     'clf__solver': ['saga'],\n",
    "#     'clf__penalty': ['none']\n",
    "#     }, {\n",
    "#     'clf__solver': ['saga'],\n",
    "#     'clf__penalty': ['elasticnet'],\n",
    "#     'clf__C': [0.1, 1.0, 10.0],\n",
    "#     'clf__l1_ratio': [0.2, 0.5, 0.8]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[('clf', clf)])\n",
    "estimator = GridSearchCV(pipe, param_grid, cv=10, scoring=['accuracy', 'f1_macro'],\n",
    "                         verbose=10, error_score=\"raise\", n_jobs=-1, refit=False)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('lr_results_2.pickle', 'rb') as f:\n",
    "    lr_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results.rename(axis=1, inplace=True, mapper={\n",
    "    'param_pca__n_components': 'pca'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_results[\n",
    "    ['mean_fit_time', 'solver', 'penalty', 'C', 'param_clf__l1_ratio', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('solver').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results[\n",
    "    ['mean_fit_time', 'solver', 'penalty', 'C', 'param_clf__l1_ratio', 'pca', 'mean_test_f1_macro', 'std_test_f1_macro',\n",
    "    'rank_test_f1_macro']\n",
    "].sort_values(by=['rank_test_f1_macro']).groupby('solver').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_features.pickle', 'rb') as f:\n",
    "    X_train, y_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "clf = LogisticRegression(max_iter=1000, solver=\"liblinear\", penalty=\"l1\", C=0.2)\n",
    "pipe = Pipeline(steps=[('pca', pca), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_features.pickle', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results[\n",
    "    ['mean_fit_time', 'metric', 'neighbors', 'pca', 'mean_test_f1_macro', 'std_test_f1_macro',\n",
    "    'rank_test_f1_macro']\n",
    "].sort_values(by=['rank_test_f1_macro']).groupby('metric').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('knn_results_1.pickle', 'rb') as f:\n",
    "    knn_results = pickle.load(f)\n",
    "\n",
    "knn_results[\n",
    "    ['mean_fit_time', 'metric', 'neighbors', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('metric').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('knn_results_5.pickle', 'rb') as f:\n",
    "    knn_results = pickle.load(f)\n",
    "\n",
    "knn_results[\n",
    "    ['mean_fit_time', 'metric', 'neighbors', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('pca').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "pca = PCA(n_components=50)\n",
    "clf = KNeighborsClassifier(metric=\"euclidean\", n_neighbors=13)\n",
    "\n",
    "pipe = Pipeline(steps=[('std', std), ('pca', pca), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tree_results_2.pickle', 'rb') as f:\n",
    "    tree_results = pickle.load(f)\n",
    "\n",
    "tree_results[\n",
    "    ['mean_fit_time', 'criterion', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('criterion').head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "pca = PCA(n_components=68)\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "pipe = Pipeline(steps=[('std', std), ('pca', pca), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('nb_results_1.pickle', 'rb') as f:\n",
    "    tree_results = pickle.load(f)\n",
    "\n",
    "tree_results[\n",
    "    ['mean_fit_time','pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=184)\n",
    "qt = QuantileTransformer()\n",
    "clf = GaussianNB()\n",
    "\n",
    "pipe = Pipeline(steps=[('pca', pca), ('qt', qt), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "pca = PCA(n_components=68)\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "pipe = Pipeline(steps=[('std', std), ('pca', pca), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('adaboost_results_1.pickle', 'rb') as f:\n",
    "    tree_results = pickle.load(f)\n",
    "\n",
    "tree_results[\n",
    "    ['mean_fit_time', 'estimators', 'lr', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('lr').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('adaboost_results_4.pickle', 'rb') as f:\n",
    "    tree_results = pickle.load(f)\n",
    "\n",
    "tree_results[\n",
    "    ['mean_fit_time', 'estimators', 'lr', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('lr').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('adaboost_results_5.pickle', 'rb') as f:\n",
    "    tree_results = pickle.load(f)\n",
    "\n",
    "tree_results[\n",
    "    ['mean_fit_time', 'estimators', 'lr', 'pca', 'mean_test_accuracy', 'std_test_accuracy',\n",
    "    'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('lr').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "pca = PCA(n_components=30)\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=1800, learning_rate=2.0)\n",
    "\n",
    "pipe = Pipeline(steps=[('std', std), ('pca', pca), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('svm_results_1.pickle', 'rb') as f:\n",
    "    svm_results = pickle.load(f)\n",
    "\n",
    "svm_results[\n",
    "    ['mean_fit_time', 'pca #components', 'kernel', 'poly degree', 'gamma', 'coef0',\n",
    "     'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('svm_results_2.pickle', 'rb') as f:\n",
    "    svm_results = pickle.load(f)\n",
    "\n",
    "svm_results[\n",
    "    ['mean_fit_time', 'pca #components', 'kernel', 'poly degree', 'gamma', 'coef0', 'C',\n",
    "     'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy']\n",
    "].sort_values(by=['rank_test_accuracy']).groupby('kernel').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "pca = PCA(n_components=250)\n",
    "clf = SVC(cache_size=8000, kernel=\"poly\", degree=4, gamma=0.001, coef0=0.5,  C=0.5)\n",
    "pipe = Pipeline(steps=[('std', std), ('pca', pca), ('clf', clf)], memory='sklearn_tmp')\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(sk.metrics.balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "disp.plot(ax=fig.gca(), xticks_rotation=\"vertical\")\n",
    "plt.savefig(\"conf_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = pipe.decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(20):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, y_score[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lw=2\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(20)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(20):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 20\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10,10))\n",
    "# plt.plot(\n",
    "#     fpr[\"micro\"],\n",
    "#     tpr[\"micro\"],\n",
    "#     label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "#     color=\"deeppink\",\n",
    "#     linestyle=\":\",\n",
    "#     linewidth=4,\n",
    "# )\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"green\"])\n",
    "for i, color in zip(range(20), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "#         color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of artist {0} (area = {1:0.2f})\".format(labels[i], roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.65, 1.01])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"roc_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Martiros Saryan\",\n",
    "\"Albrecht Durer\",\n",
    "\"Zdislav Beksinski\",\n",
    "\"Claude Monte\",\n",
    "\"Pyotr Konchalovsky\",\n",
    "\"Raphael Kirchner\",\n",
    "\"Rembrandt\",\n",
    "\"Gustave Dore\",\n",
    "\"Boris Kustodiev\",\n",
    "\"Ivan Aivazovsky\",\n",
    "\"Pablo Picasso\",\n",
    "\"Marc Chagall\",\n",
    "\"Ivan Shishkin\",\n",
    "\"Paul Cezanne\",\n",
    "\"Camille Pissarro\",\n",
    "\"Pierre-Auguste Renoir\",\n",
    "\"Paul Gauguin\",\n",
    "\"Ilya Repin\",\n",
    "\"Giovanni Battista Piranesi\",\n",
    "\"John Singer Sargent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "oZw3lh8d_e8N",
    "YDEHfMGkGV8J",
    "Pf69K7s6PLiz",
    "nOS59AIPPlfj",
    "1YTNZjsfdh8W",
    "9eikXM0IP0XN"
   ],
   "name": "Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0dff3ccc15ab40399ea1b3749c9e7f01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27a3c8ce545f477d8b3cb2d4358b72aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_709f170efcf74bd484939ba2ff39dfb1",
      "max": 2005,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a368c89b81e3463a822042826c25b5c9",
      "value": 2005
     }
    },
    "4e9cd596a218497a94940db9ee24471d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "530861e7ab3146cd85d239b36fe8c228": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "709f170efcf74bd484939ba2ff39dfb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "761dfdab66bf4abf8b4b5be7041edaa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78b3403352eb4fc68274d87602e3fa38",
      "placeholder": "​",
      "style": "IPY_MODEL_0dff3ccc15ab40399ea1b3749c9e7f01",
      "value": "100%"
     }
    },
    "78b3403352eb4fc68274d87602e3fa38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8da11b77ccb2437cb1ceaa82a30986ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a368c89b81e3463a822042826c25b5c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3fa098265cb41a491a00db86483b1d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_761dfdab66bf4abf8b4b5be7041edaa0",
       "IPY_MODEL_27a3c8ce545f477d8b3cb2d4358b72aa",
       "IPY_MODEL_f007e15b78cf449c8d93945b0a5378d7"
      ],
      "layout": "IPY_MODEL_4e9cd596a218497a94940db9ee24471d"
     }
    },
    "f007e15b78cf449c8d93945b0a5378d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8da11b77ccb2437cb1ceaa82a30986ac",
      "placeholder": "​",
      "style": "IPY_MODEL_530861e7ab3146cd85d239b36fe8c228",
      "value": " 2005/2005 [01:04&lt;00:00, 40.79it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
